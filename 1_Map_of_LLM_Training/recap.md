# The Finetuning Landscape - A Map of Modern LLM Training

![](https://substackcdn.com/image/fetch/$s_!_Yph!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff1909018-fbb6-4a19-8eb3-7cce5c333837_1920x1080.png)


## Transformer 101

### The Attention Mechanism 
### Preparing the Ground for Transformers
#### Self-Attention 
#### Positional Encoding
#### Multi-Head Attention

### Bringing It All Together: The Transformer



## The 3 Transformer architectures

### Encoder-Only Transformers
### Encoder–Decoder Transformers
### Decoder-Only Transformers 
### The Scaling Laws



## The LLM Training Pipeline

### Pretraining 101
#### What Happens During Pretraining
#### Self-Supervised Learning
#### The output of pretraining: A Base Model


## References


